{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Vectara & Tonic Validate",
   "id": "cf9cbfa3db70b055"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:12:44.039091Z",
     "start_time": "2024-04-18T13:12:43.898994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import requests\n",
    "# importing necessary functions from dotenv library\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# loading variables from .env file\n",
    "load_dotenv()"
   ],
   "id": "a1742e50164b6c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:12:44.424518Z",
     "start_time": "2024-04-18T13:12:44.411299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TONIC_VALIDATE_API_KEY = os.getenv(\"TONIC_VALIDATE_API_KEY\")\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "CUSTOMER_ID = 43437896\n",
    "CORPUS_ID = 3\n",
    "SERVING_ENDPOINT = \"api.vectara.io\""
   ],
   "id": "ac0640ccfae89b0b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:12:45.302152Z",
     "start_time": "2024-04-18T13:12:45.288904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _get_query_json(customer_id: int, corpus_id: int, query_value: str, num_results: int):\n",
    "    \"\"\"Returns a query JSON.\"\"\"\n",
    "    query = {\n",
    "        \"query\": [\n",
    "            {\n",
    "                \"query\": query_value,\n",
    "                \"num_results\": num_results,\n",
    "                \"corpus_key\": [{\"customer_id\": customer_id, \"corpus_id\": corpus_id}],\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "    return json.dumps(query)\n",
    "\n",
    "\n",
    "def get_query(query: str, num_results: int = 1):\n",
    "    \"\"\"Queries the data.\n",
    "  \n",
    "    Args:\n",
    "        customer_id: Unique customer ID in vectara platform.\n",
    "        corpus_id: ID of the corpus to which data needs to be indexed.\n",
    "        query_address: Address of the querying server. e.g., api.vectara.io\n",
    "        api_key: A valid API key with query access on the corpus.\n",
    "  \n",
    "    Returns:\n",
    "        (response, True) in case of success and returns (error, False) in case of failure.\n",
    "    \"\"\"\n",
    "    post_headers = {\n",
    "        \"customer-id\": f\"{CUSTOMER_ID}\",\n",
    "        \"x-api-key\": API_KEY\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"https://{SERVING_ENDPOINT}/v1/query\",\n",
    "        data=_get_query_json(CUSTOMER_ID, CORPUS_ID, query, num_results),\n",
    "        verify=True,\n",
    "        headers=post_headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        logging.error(\"Query failed with code %d, reason %s, text %s\",\n",
    "                      response.status_code,\n",
    "                      response.reason,\n",
    "                      response.text)\n",
    "        return response, False\n",
    "\n",
    "    message = response.json()\n",
    "    if (message[\"status\"] and\n",
    "            any(status[\"code\"] != \"OK\" for status in message[\"status\"])):\n",
    "        logging.error(\"Query failed with status: %s\", message[\"status\"])\n",
    "        return message[\"status\"], False\n",
    "\n",
    "    for response_set in message[\"responseSet\"]:\n",
    "        for status in response_set[\"status\"]:\n",
    "            if status[\"code\"] != \"OK\":\n",
    "                return status, False\n",
    "\n",
    "    return message, True"
   ],
   "id": "8c7dcb812751e86b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:12:54.167772Z",
     "start_time": "2024-04-18T13:12:54.153242Z"
    }
   },
   "cell_type": "code",
   "source": "SERVING_ENDPOINT",
   "id": "34d4809f98592f4f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'api.vectara.io'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:12:57.371543Z",
     "start_time": "2024-04-18T13:12:56.624019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"How to get hire at gitlab?\"\n",
    "\n",
    "response, status = get_query(query)\n"
   ],
   "id": "4f1f145aee0cccb3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:13:02.393539Z",
     "start_time": "2024-04-18T13:13:02.384272Z"
    }
   },
   "cell_type": "code",
   "source": "response[\"responseSet\"][0][\"response\"][0][\"text\"]",
   "id": "65642c977bccc3e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the effort to be as transparent as possible and avoid sending multiple competing GitLab offers, there will be an added step to the process after your final interview where you will discuss with your recruiter which role you’re interested in before any official offer documents can be sent.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:13:05.087363Z",
     "start_time": "2024-04-18T13:13:05.066888Z"
    }
   },
   "cell_type": "code",
   "source": "response[\"responseSet\"][0]",
   "id": "cabebec983fae537",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': [{'text': 'In the effort to be as transparent as possible and avoid sending multiple competing GitLab offers, there will be an added step to the process after your final interview where you will discuss with your recruiter which role you’re interested in before any official offer documents can be sent.',\n",
       "   'score': 0.7387057,\n",
       "   'metadata': [{'name': 'title', 'value': 'Interview Process FAQs'},\n",
       "    {'name': 'lang', 'value': 'eng'},\n",
       "    {'name': 'section', 'value': '1'},\n",
       "    {'name': 'offset', 'value': '1664'},\n",
       "    {'name': 'len', 'value': '292'}],\n",
       "   'documentIndex': 0,\n",
       "   'corpusKey': {'customerId': 0,\n",
       "    'corpusId': 3,\n",
       "    'semantics': 'DEFAULT',\n",
       "    'dim': [],\n",
       "    'metadataFilter': '',\n",
       "    'lexicalInterpolationConfig': None},\n",
       "   'resultOffset': 0,\n",
       "   'resultLength': 292}],\n",
       " 'status': [],\n",
       " 'document': [{'id': 'Gitlab Interview Process FAQs.docx',\n",
       "   'metadata': [{'name': 'X-TIKA:Parsed-By',\n",
       "     'value': 'org.apache.tika.parser.microsoft.ooxml.OOXMLParser'},\n",
       "    {'name': 'extended-properties:DocSecurityString', 'value': 'None'},\n",
       "    {'name': 'Content-Type',\n",
       "     'value': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'}]}],\n",
       " 'summary': [],\n",
       " 'futureId': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing with benchmark QA",
   "id": "a1de8ac6660f810"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:13:08.887969Z",
     "start_time": "2024-04-18T13:13:08.860264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load questions from qa_pairs.json\n",
    "import json\n",
    "import tqdm\n",
    "qa_pairs = []\n",
    "with open('./data/QA_gitlab.json', 'r') as qa_file:\n",
    "    qa_pairs = json.load(qa_file)\n",
    "\n",
    "question_list = [qa_pair['question'] for qa_pair in qa_pairs]\n",
    "print(\"Questions:\\n\" + \"\\n\".join(question_list[:4]))\n"
   ],
   "id": "19a0484a0819adbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions:\n",
      "How can candidates request a reasonable accommodation for their interview process at GitLab?\n",
      "I've started the interview process at GitLab, but haven't heard back from anyone recently. What should I do?\n",
      "Can I have the hiring team's email addresses so I can send them a note?\n",
      "Can I interview for multiple roles at the same time?\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:13:09.589357Z",
     "start_time": "2024-04-18T13:13:09.573854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "answer_list = [qa_pair['answer'] for qa_pair in qa_pairs]\n",
    "print(\"Answers:\\n\" + \"\\n\".join(answer_list[:4]))"
   ],
   "id": "d916472571a3d604",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers:\n",
      "Candidates can request a reasonable accommodation by reaching out to ces@gitlab.com. The Candidate Experience team along with Talent Acquisition leadership will collaborate with the candidate to define and accommodate their needs, which may include translation services, the use of additional services or assistive technologies, and assistance in setting up Closed Captioning for interviews.\n",
      "Feel free to send an email to your Recruiter to get a status update on where you are in the interview process.\n",
      "If you'd like to send a note to the hiring team, please send it to your Recruiter and they will forward it on.\n",
      "Yes, you can apply for multiple roles at the same time. However, keep in mind that you will need to complete a full interview process for each role you apply to. Additionally, the recruiting team will only process 3 of your applications at a time based on which ones you decide to prioritize.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:13:15.623689Z",
     "start_time": "2024-04-18T13:13:14.780515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tonic_validate import Benchmark\n",
    "question_list = [qa_pair['question'] for qa_pair in qa_pairs]\n",
    "answer_list = [qa_pair['answer'] for qa_pair in qa_pairs]\n",
    "\n",
    "benchmark = Benchmark(questions=question_list, answers=answer_list)"
   ],
   "id": "e88475b0da8a8043",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:15:03.661376Z",
     "start_time": "2024-04-18T13:15:01.199973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tonic_validate import ValidateScorer\n",
    "\n",
    "scorer = ValidateScorer()\n",
    "response_scores = scorer.score(benchmark, get_query, scoring_parallelism=2, callback_parallelism=2)"
   ],
   "id": "fa6be49f36c6bee4",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtonic_validate\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ValidateScorer\n\u001B[0;32m      3\u001B[0m scorer \u001B[38;5;241m=\u001B[39m ValidateScorer()\n\u001B[1;32m----> 4\u001B[0m response_scores \u001B[38;5;241m=\u001B[39m \u001B[43mscorer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbenchmark\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mget_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring_parallelism\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback_parallelism\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\01_Freelance\\projects\\Advanced_RAG\\venv\\lib\\site-packages\\tonic_validate\\validate_scorer.py:128\u001B[0m, in \u001B[0;36mValidateScorer.score\u001B[1;34m(self, benchmark, callback, callback_parallelism, scoring_parallelism)\u001B[0m\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m LLMResponse(callback_response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllm_answer\u001B[39m\u001B[38;5;124m\"\u001B[39m], callback_response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllm_context_list\u001B[39m\u001B[38;5;124m\"\u001B[39m], item)\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ThreadPoolExecutor(max_workers\u001B[38;5;241m=\u001B[39mcallback_parallelism) \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[1;32m--> 128\u001B[0m     responses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mexecutor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcreate_response\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbenchmark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscore_responses(responses, scoring_parallelism)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:621\u001B[0m, in \u001B[0;36mExecutor.map.<locals>.result_iterator\u001B[1;34m()\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m fs:\n\u001B[0;32m    619\u001B[0m     \u001B[38;5;66;03m# Careful not to keep a reference to the popped future\u001B[39;00m\n\u001B[0;32m    620\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 621\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[43m_result_or_cancel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    622\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    623\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m _result_or_cancel(fs\u001B[38;5;241m.\u001B[39mpop(), end_time \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic())\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:319\u001B[0m, in \u001B[0;36m_result_or_cancel\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 319\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfut\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    321\u001B[0m         fut\u001B[38;5;241m.\u001B[39mcancel()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:458\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m--> 458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    460\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 403\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[0;32m    404\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    405\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[0;32m    406\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py:58\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 58\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfn(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs)\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "File \u001B[1;32m~\\Desktop\\01_Freelance\\projects\\Advanced_RAG\\venv\\lib\\site-packages\\tonic_validate\\validate_scorer.py:125\u001B[0m, in \u001B[0;36mValidateScorer.score.<locals>.create_response\u001B[1;34m(item)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_response\u001B[39m(item: BenchmarkItem) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResponse:\n\u001B[0;32m    124\u001B[0m     callback_response \u001B[38;5;241m=\u001B[39m callback(item\u001B[38;5;241m.\u001B[39mquestion)\n\u001B[1;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m LLMResponse(\u001B[43mcallback_response\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mllm_answer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m, callback_response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllm_context_list\u001B[39m\u001B[38;5;124m\"\u001B[39m], item)\n",
      "\u001B[1;31mTypeError\u001B[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:14.034393Z",
     "start_time": "2024-04-18T13:17:12.576329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tonic_validate import ValidateScorer\n",
    "\n",
    "# scorer = ValidateScorer(model_evaluator=\"gpt-3.5-turbo\", max_parsing_retries=10)\n",
    "scorer = ValidateScorer()\n",
    "response_scores = scorer.score(benchmark, get_query)"
   ],
   "id": "b03c43efa3f903fd",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# scorer = ValidateScorer(model_evaluator=\"gpt-3.5-turbo\", max_parsing_retries=10)\u001B[39;00m\n\u001B[0;32m      4\u001B[0m scorer \u001B[38;5;241m=\u001B[39m ValidateScorer()\n\u001B[1;32m----> 5\u001B[0m response_scores \u001B[38;5;241m=\u001B[39m \u001B[43mscorer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbenchmark\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mget_query\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\01_Freelance\\projects\\Advanced_RAG\\venv\\lib\\site-packages\\tonic_validate\\validate_scorer.py:128\u001B[0m, in \u001B[0;36mValidateScorer.score\u001B[1;34m(self, benchmark, callback, callback_parallelism, scoring_parallelism)\u001B[0m\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m LLMResponse(callback_response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllm_answer\u001B[39m\u001B[38;5;124m\"\u001B[39m], callback_response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllm_context_list\u001B[39m\u001B[38;5;124m\"\u001B[39m], item)\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ThreadPoolExecutor(max_workers\u001B[38;5;241m=\u001B[39mcallback_parallelism) \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[1;32m--> 128\u001B[0m     responses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mexecutor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcreate_response\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbenchmark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscore_responses(responses, scoring_parallelism)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:621\u001B[0m, in \u001B[0;36mExecutor.map.<locals>.result_iterator\u001B[1;34m()\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m fs:\n\u001B[0;32m    619\u001B[0m     \u001B[38;5;66;03m# Careful not to keep a reference to the popped future\u001B[39;00m\n\u001B[0;32m    620\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 621\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[43m_result_or_cancel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    622\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    623\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m _result_or_cancel(fs\u001B[38;5;241m.\u001B[39mpop(), end_time \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic())\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:319\u001B[0m, in \u001B[0;36m_result_or_cancel\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 319\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfut\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    321\u001B[0m         fut\u001B[38;5;241m.\u001B[39mcancel()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:458\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m--> 458\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    460\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 403\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[0;32m    404\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    405\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[0;32m    406\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py:58\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 58\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfn(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs)\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "File \u001B[1;32m~\\Desktop\\01_Freelance\\projects\\Advanced_RAG\\venv\\lib\\site-packages\\tonic_validate\\validate_scorer.py:125\u001B[0m, in \u001B[0;36mValidateScorer.score.<locals>.create_response\u001B[1;34m(item)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_response\u001B[39m(item: BenchmarkItem) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResponse:\n\u001B[0;32m    124\u001B[0m     callback_response \u001B[38;5;241m=\u001B[39m callback(item\u001B[38;5;241m.\u001B[39mquestion)\n\u001B[1;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m LLMResponse(\u001B[43mcallback_response\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mllm_answer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m, callback_response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mllm_context_list\u001B[39m\u001B[38;5;124m\"\u001B[39m], item)\n",
      "\u001B[1;31mTypeError\u001B[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import os\n",
    "from tonic_validate import ValidateApi\n",
    "from tonic_validate.metrics import AnswerSimilarityMetric, RetrievalPrecisionMetric, AugmentationPrecisionMetric, AnswerConsistencyMetric\n",
    "from llama_index.evaluation import TonicValidateEvaluator\n",
    "import requests"
   ],
   "id": "f2fad1b668714036"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "openai_responses, openai_context = [], []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Go through all questions and get responses from openai assistant\n",
    "for question in tqdm(question_list[len(openai_responses):]):\n",
    "    # If there is an exception, try again until we reach 3 tries at max\n",
    "    max_tries = 3\n",
    "    while True:\n",
    "        try:\n",
    "            openai_response = get_response(question)\n",
    "            openai_responses.append(openai_response)\n",
    "\topenai_context.append(openai_response[1])\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            max_tries -= 1\n",
    "            if max_tries == 0:\n",
    "                raise e\n",
    "            continue"
   ],
   "id": "436507fbd182d67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tonic_validate import ValidateScorer, Benchmark, BenchmarkItem, LLMResponse, BenchmarkItem, Run\n",
    "from tonic_validate.metrics import AnswerSimilarityMetric\n",
    "\n",
    "score_calculator = RagScoresCalculator(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    answer_similarity_score=True,\n",
    ")\n",
    "\n",
    "# Score the results\n",
    "openai_batch_scores = score_calculator.score_batch(\n",
    "    question_list=question_list,\n",
    "    reference_answer_list=answer_list,\n",
    "    llm_answer_list=openai_responses,\n",
    ")\n",
    "openai_scores_df = openai_batch_scores.to_dataframe()\n",
    "# Remove overall_score column since we are only using one stat\n",
    "openai_scores_df = openai_scores_df.drop(columns=['overall_score'])\n",
    "openai_scores_df.describe()"
   ],
   "id": "18f71fb59a0d5c3b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
